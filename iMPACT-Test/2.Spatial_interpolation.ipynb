{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1c81574",
   "metadata": {},
   "source": [
    "# Spatial Interpolation of Measured Data\n",
    "\n",
    "<img src=\"images/soil_sampling.png\" style=\"width: 300px; float:right\"><h>This Jupyter Notebook demonstrates how to spatially interpolate data measured at discrete locations across a catchment. For example, the soil loss rates derived from field measurements, such as those obtained using fallout radionuclide techniques or soil erodibility estimated from soil texture analysis. This process allows us to create a continuous representation of soil loss across the entire catchment, even in areas where direct measurements are not available.\n",
    "    \n",
    "\n",
    "## First we need to import the necessary libraries and iMPACT-tools    \n",
    "\n",
    "We begin by importing the Python libraries required for data manipulation, geospatial operations, visualization, and interpolation.\n",
    "    \n",
    "##### Import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23376715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np  # For numerical operations and array handling\n",
    "import pandas as pd  # For handling tabular data (e.g., soil loss estimates)\n",
    "import rasterio  # For reading and writing raster (geospatial) data\n",
    "import matplotlib.pyplot as plt  # For plotting and visualizations\n",
    "from ipywidgets import interactive, Dropdown  # For creating interactive widgets\n",
    "from scipy import interpolate  # For spatial interpolation methods\n",
    "from scipy.spatial.distance import pdist\n",
    "# Import the necessary iMPACTools (you can find these tools in the Python files stored in the */iMPACtools* folder)\n",
    "os.chdir('..') # change the current working directory to the parent directory\n",
    "from iMPACTools.file_IO import open_raster, save_as_raster\n",
    "from iMPACTools.spatial_interpolation import idw, loocv_idw, spatial_uncertainty\n",
    "from iMPACTools.spatial_interpolation import ordinary_kriging, spherical_variogram, gaussian_variogram, exponential_variogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf066ab",
   "metadata": {},
   "source": [
    "## Choose the case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadf52bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of case studies (folders in the Case_studies directory)\n",
    "case_study = Dropdown(options=os.listdir('Case_studies'),description='Case Study:')\n",
    "display(case_study)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2382c0e",
   "metadata": {},
   "source": [
    "<img src=\"images/open_raster.png\" style=\"width: 200px; float:right\"><h2>Load the DEM</h2><h>\n",
    "    \n",
    "##### Open the file and plot the DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad27241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Digital Elevation Model (DEM) raster file\n",
    "dem, metadata = open_raster(f'Case_studies/{case_study.value}/topo/','dem_catchment.tif')\n",
    "\n",
    "# Get the number of rows and columns in the DEM\n",
    "n_rows, n_cols = dem.shape\n",
    "grid_x, grid_y = np.meshgrid(np.arange(0, n_rows), np.arange(0, n_cols), indexing='ij')\n",
    "\n",
    "# Plot DEM\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(dem, cmap='terrain', origin='upper') # 'terrain' colormap is suitable for visualizing elevation.\n",
    "plt.colorbar(label='Elevation (m)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fa9062",
   "metadata": {},
   "source": [
    "## Choose and load the point data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34736b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of data folders\n",
    "data_folder = Dropdown(options=os.listdir(f'Case_studies/{case_study.value}'),description='data folder:')\n",
    "display(data_folder)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deec996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of data files\n",
    "data_file = Dropdown(options=os.listdir(f'Case_studies/{case_study.value}/{data_folder.value}'),description='data file:')\n",
    "display(data_file)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cb56a8",
   "metadata": {},
   "source": [
    "Now, we load the data from an Excel file. This data should contain the location (coordinates) in the first two columns ***X*** and ***Y*** and the corresponding values for each measurement point in the third column ***Z***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0584500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from an Excel file\n",
    "data_path = f'Case_studies/{case_study.value}/{data_folder.value}/{data_file.value}'\n",
    "data_df = pd.read_excel(data_path, index_col = 'ID')\n",
    "data_df.head(10) # Display the first few rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e8c39f",
   "metadata": {},
   "source": [
    "## Convert UTM coordinates to gridcell indices (row number, column number)\n",
    "Convert soil loss sample locations from UTM coordinates to raster grid indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d9f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_ids, col_ids = [], [] # Initialize the lists to store row and column indices\n",
    "n_points = data_df.shape[0]  # Number of soil loss points\n",
    "\n",
    "# Convert each coordinate to a corresponding row and column in the DEM grid\n",
    "transform = metadata['transform']\n",
    "for i in range(n_points):\n",
    "    col = (data_df['X'].iloc[i] - transform[2]) / transform[0]\n",
    "    row = (data_df['Y'].iloc[i] - transform[5]) / transform[4]\n",
    "    row_ids.append(int(np.round(row))) \n",
    "    col_ids.append(int(np.round(col)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc785999",
   "metadata": {},
   "source": [
    "## Plot the DEM and Sample Points\n",
    "   - The DEM is displayed using a terrain colormap (`cmap='terrain'`).\n",
    "   - The extracted elevation points are overlaid on the DEM using `plt.scatter()`, with colors representing their elevation values.\n",
    "   - A color bar, legend, and title are added for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8192d4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = data_file.value.split('.')[0]\n",
    "# Plot DEM with sampling points\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(dem, cmap='terrain', origin='upper')\n",
    "plt.colorbar(label='Elevation (m)')\n",
    "plt.scatter(col_ids, row_ids, edgecolor='k', cmap='coolwarm', label='sampling locations')\n",
    "plt.title(f'Sampling locations - {data_type} (n={n_points})')\n",
    "plt.legend()\n",
    "for i, txt in enumerate(data_df['Z']):\n",
    "    plt.annotate(f'{txt:.2f}', (col_ids[i], row_ids[i]), textcoords=\"offset points\", xytext=(0,5), ha='center', fontsize=8, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1b9309",
   "metadata": {},
   "source": [
    "## Interpolate data across the catchment\n",
    "Now we perform the spatial interpolation.  We use `scipy.interpolate.griddata` to interpolate the measured values from the scattered points to a regular grid covering the entire DEM.  Several interpolation methods are available (nearest neighbor, linear, cubic).\n",
    "\n",
    "We also use `ipywidgets` to add interactivity: a dropdown menu allows the user to select different interpolation methods and see the resulting changes in the interpolated soil loss map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb65bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_spatial_interpolation(inter_method):\n",
    "    \n",
    "    # Perform interpolation with the selected method\n",
    "    \n",
    "    inter_map = interpolate.griddata(np.column_stack([row_ids, col_ids]), data_df['Z'], (grid_x, grid_y), \n",
    "                                    method=inter_method)\n",
    "    inter_map[np.isnan(dem)] = np.nan\n",
    "    \n",
    "    # Plot interpolated soil loss map\n",
    "    plt.figure(figsize=(10, 5))  # Set the figure size\n",
    "    plt.imshow(inter_map, cmap = 'terrain')  # Display the interpolated map\n",
    "    plt.colorbar(label=f'{data_type}') # Add a color bar indicating soil loss rates\n",
    "    plt.scatter(col_ids, row_ids, edgecolor='k') # Overlay the sampling pointds\n",
    "    plt.title(f'Interpolated map (method = {inter_method})')  # Add a title\n",
    "    plt.show()  # Display the plot\n",
    "    \n",
    "    # Define the output file path\n",
    "    output_path = f'Case_studies/{case_study.value}/{data_folder.value}/'\n",
    "    output_file = f'{data_type}_interpolated_map({inter_method}).tif'\n",
    "\n",
    "    save_as_raster(output_path, output_file, inter_map, metadata)\n",
    "    \n",
    "    print(f\"Interpolated map saved to: {output_path+output_file}\")\n",
    "\n",
    "# Create an interactive widget for method selection\n",
    "interactive(interactive_spatial_interpolation, inter_method = ['nearest', 'linear', 'cubic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f438d3",
   "metadata": {},
   "source": [
    "### Inverse Distance Weighting\n",
    "IDW is a spatial interpolation technique used to estimate unknown values at specific locations based on values from nearby known points. It assumes that **points closer to the location of interest have more influence (i.e., more weight) than those farther away**.\n",
    "\n",
    "#### üìê How does it work?\n",
    "\n",
    "For any location you want to estimate, IDW computes a **weighted average** of the surrounding known values. The weights are **inversely related to distance**, typically raised to a power \\( p \\):\n",
    "\n",
    "$\n",
    "\\hat{z}(x_0) = \\frac{ \\sum_{i=1}^n w_i \\cdot z(x_i) }{ \\sum_{i=1}^n w_i }\n",
    "$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $ \\hat{z}(x_0) $: estimated value at the unknown location $ x_0 $\n",
    "- $ z(x_i) $: value at the known location $ x_i $\n",
    "- $ w_i = \\frac{1}{d(x_i, x_0)^p} $: weight for point $ i $, based on its distance to $ x_0 $\n",
    "- $ p $: power parameter (commonly $ p = 2 $)\n",
    "\n",
    "$ p $ controls how quickly influence decreases with distance.\n",
    "- **Higher \\( p \\)** ‚Üí more influence from nearer points (more \"localized\").\n",
    "- **Lower \\( p \\)** ‚Üí more influence from distant points (more \"global\").\n",
    "\n",
    "| \\( p \\) value | Effect |\n",
    "|--------------|--------|\n",
    "| 1            | Linear inverse |\n",
    "| 2            | Squared inverse (common) |\n",
    "| >2           | Strong local influence |\n",
    "\n",
    "---\n",
    "#### ‚úÖ Advantages\n",
    "- Simple and intuitive\n",
    "- No need to fit a model\n",
    "\n",
    "#### ‚ùå Limitations\n",
    "- Does **not** consider trends or spatial structure in the data\n",
    "- The optimal power parameter value needs to be estimated\n",
    "\n",
    "#### üß≠ Use Cases\n",
    "- Environmental data mapping (e.g., soil properties, rainfall)\n",
    "- Real-time sensor networks\n",
    "\n",
    "---\n",
    "\n",
    "#### Let's define the function to compute the IDW interpolation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739facb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idw(points, values, xi, power=2):\n",
    "    \"\"\"\n",
    "    Classic power-based Inverse Distance Weighting (IDW) interpolation over a 2D grid.\n",
    "\n",
    "    Parameters:\n",
    "        points : (n, 2) array\n",
    "            Known data point coordinates.\n",
    "        values : (n,) array\n",
    "            Values at the data points.\n",
    "        xi : tuple of 2D arrays (grid_x, grid_y)\n",
    "            Coordinates where interpolation is to be computed.\n",
    "        power : float\n",
    "            Power parameter for inverse distance weighting (default = 2).\n",
    "\n",
    "    Returns:\n",
    "        zi : 2D array\n",
    "            Interpolated grid of values.\n",
    "    \"\"\"\n",
    "    grid_x, grid_y = xi\n",
    "    xi_flat = np.column_stack((grid_x.ravel(), grid_y.ravel()))\n",
    "    \n",
    "    dists = np.linalg.norm(xi_flat[:, None, :] - points[None, :, :], axis=2)\n",
    "\n",
    "    # Avoid division by zero by setting minimum distance\n",
    "    dists[dists == 0] = 1e-10\n",
    "\n",
    "    # Compute inverse distance weights\n",
    "    weights = 1.0 / dists**power\n",
    "    weights_sum = np.sum(weights, axis=1)\n",
    "\n",
    "    # Compute interpolated values\n",
    "    zi_flat = np.sum(weights * values, axis=1) / weights_sum\n",
    "    zi = zi_flat.reshape(grid_x.shape)\n",
    "\n",
    "    return zi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3076cd",
   "metadata": {},
   "source": [
    "#### Now let's perform leave-one-out cross-validation (LOOCV) to estimate the error produced by different power values\n",
    "For different power parameter values, **LOOCV** evaluates model performance by iteratively removing each data point, predicting its value with the rest, and calculating error metrics like:\n",
    "\n",
    "- **RMSE** (Root Mean Square Error): emphasizes larger errors.\n",
    "\n",
    "- **MAE** (Mean Absolute Error): gives equal weight to all errors.\n",
    "\n",
    "This can help us choose the **optimal power parameter value** (minimum error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b724af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_LOOCV(max_power):\n",
    "    # List of power parameters to test for the IDW interpolation\n",
    "    step = 0.5\n",
    "    power_values = np.arange(0, max_power+step,step)\n",
    "    results = loocv_idw(np.column_stack([row_ids, col_ids]), data_df['Z'].values, power_values)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(power_values, [results[p]['rmse'] for p in power_values], 'bo-', label='RMSE') # Plot RMSE for each power value\n",
    "    plt.plot(power_values, [results[p]['mae'] for p in power_values], 'ro-', label='MAE') # Plot MAE for each power value\n",
    "    plt.xlabel('Power Parameter value')\n",
    "    plt.ylabel('Error Metric')\n",
    "    plt.title('IDW Leave-one-out error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "interactive(interactive_LOOCV, max_power=(0.5,10,0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75fac23",
   "metadata": {},
   "source": [
    "#### Now we define the optimal power parameter value and run the function and plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9522bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_IDW(power_value):\n",
    "    # Run the function\n",
    "    inter_map_idw = idw(np.column_stack([row_ids, col_ids]), data_df['Z'].values, (grid_x, grid_y), power=power_value)\n",
    "    inter_map_idw[np.isnan(dem)] = np.nan\n",
    "\n",
    "    # Plot interpolated map\n",
    "    plt.figure(figsize=(10, 5))  # Set the figure size\n",
    "    plt.imshow(inter_map_idw, cmap = 'terrain')  # Display the interpolated map\n",
    "    plt.colorbar(label=f'{data_type}') # Add a color bar\n",
    "    plt.scatter(col_ids, row_ids, edgecolor='k') # Overlay the sampling points\n",
    "    plt.title(f'Interpolated map (method: IDW)')\n",
    "    plt.show()  # Display the plot \n",
    "    \n",
    "    return power_value\n",
    "    \n",
    "interactive_idw_figure = interactive(interactive_IDW, power_value=(0,10,0.5))\n",
    "display(interactive_idw_figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb46653",
   "metadata": {},
   "source": [
    "#### Define the optimal power paramater value  and save the interpolated map as a raster file\n",
    "Finally, we save the interpolated soil loss map as a GeoTIFF raster file. This allows you to use the map in other GIS software or analyses.  It's crucial to preserve the geospatial information (the transform) so the map is correctly georeferenced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5055194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimal power parameter value\n",
    "power_value = interactive_idw_figure.result\n",
    "\n",
    "# Run the function\n",
    "inter_map_idw = idw(np.column_stack([row_ids, col_ids]), data_df['Z'].values, (grid_x, grid_y), power=power_value)\n",
    "inter_map_idw[np.isnan(dem)] = np.nan\n",
    "\n",
    "# Define the output file path\n",
    "output_path = f'Case_studies/{case_study.value}/{data_folder.value}/'\n",
    "output_file = f'{data_type}_interpolated_map(IDW).tif'\n",
    "\n",
    "save_as_raster(output_path, output_file, inter_map_idw, metadata)\n",
    "\n",
    "print(f\"Interpolated map saved to: {output_path+output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61d5141",
   "metadata": {},
   "source": [
    "### Kriging\n",
    "**Kriging** is a **geostatistical interpolation** method that not only considers the distance between known and unknown points but also accounts for the **spatial autocorrelation** (i.e., how values relate to each other in space).\n",
    "\n",
    "Named after D.G. Krige, a South African mining engineer, it's widely used in geology, soil science, environmental studies, and more.\n",
    "\n",
    "#### üîç How does Kriging work?\n",
    "Kriging estimates a value at an unknown location as a **weighted sum** of nearby known values, **like IDW**, but the **weights are not just based on distance**‚Äîthey are based on how the variable behaves spatially.\n",
    "\n",
    "$\n",
    "\\hat{z}(x_0) = \\sum_{i=1}^n w_i \\cdot z(x_i)\n",
    "$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $ \\hat{z}(x_0) $: estimated value at unknown location\n",
    "- $ z(x_i) $: known values\n",
    "- $ w_i $: weights computed based on a **variogram** model\n",
    "\n",
    "#### üßÆ Key Difference: The Variogram\n",
    "Kriging requires a **variogram** to model spatial correlation. The **variogram** describes how similar points are as a function of distance:\n",
    "\n",
    "$\n",
    "\\gamma(h) = \\frac{1}{2} \\text{Var}(z(x) - z(x + h))\n",
    "$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $ h $: distance between points\n",
    "- $ \\gamma(h) $: semivariance (increases with distance)\n",
    "\n",
    "üìå The variogram helps define how the weights should be distributed based on spatial patterns, not just distance.\n",
    "\n",
    "#### üîß Types of Kriging\n",
    "\n",
    "- **Ordinary Kriging**: assumes constant but unknown mean\n",
    "- **Simple Kriging**: assumes known mean\n",
    "- **Universal Kriging**: accounts for trends (e.g., elevation or slope)\n",
    "- **Indicator Kriging**: used for categorical data or probabilities\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Advantages\n",
    "\n",
    "- More accurate than IDW when spatial correlation is present\n",
    "- Can model spatial trends and anisotropy (directional variability)\n",
    "\n",
    "#### ‚ùå Disadvantages\n",
    "\n",
    "- More complex: requires variogram fitting\n",
    "- Slower than IDW\n",
    "- Sensitive to the quality of the variogram\n",
    "\n",
    "#### üß≠ When to use Kriging over IDW?\n",
    "\n",
    "| Situation                          | Recommended Method |\n",
    "|-----------------------------------|---------------------|\n",
    "| You want speed and simplicity     | **IDW**             |\n",
    "| You have few data points          | **IDW**             |\n",
    "| You expect spatial structure      | **Kriging**         |\n",
    "| You have dense, high-quality data | **Kriging**         |\n",
    "\n",
    "---\n",
    "\n",
    "#### Let's run the function to compute the Ordinary Kriging interpolation method and plot the results\n",
    "\n",
    "In Ordinary Kriging, the predicted value at a point is a weighted average of the known values. The weights are calculated by solving a system based on variogram values, but only the relative differences in the variogram values matter ‚Äî not the absolute scale. The sill value doesn't affect the final Kriging interpolation because Ordinary Kriging is invariant to the scale of the variogram ‚Äî it's a relative method based on covariance ratios, not absolute values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9441b4e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def interactive_ordinary_kriging(variogram, sill, range_,num_bins):\n",
    "    if variogram == 'spherical':\n",
    "        variogram_model = spherical_variogram\n",
    "    elif variogram == 'gaussian':\n",
    "        variogram_model = gaussian_variogram\n",
    "    elif variogram == 'exponential':\n",
    "        variogram_model = exponential_variogram\n",
    "    \n",
    "    # Run the function\n",
    "    inter_map_kriging,sill, range_ = ordinary_kriging(np.column_stack([row_ids, col_ids]), data_df['Z'], (grid_x, grid_y), \n",
    "                                             variogram_model, sill, range_,num_bins)\n",
    "    inter_map_kriging[np.isnan(dem)] = np.nan\n",
    "\n",
    "    # Plot interpolated soil loss map\n",
    "    plt.figure(figsize=(10, 5))  # Set the figure size\n",
    "    plt.imshow(inter_map_kriging, cmap = 'terrain')  # Display the interpolated map\n",
    "    plt.colorbar(label=f'{data_type}') # Add a color bar indicating soil loss rates\n",
    "    plt.scatter(col_ids, row_ids, edgecolor='k') # Overlay the sampling points\n",
    "    plt.title(f'Interpolated map (method = kriging | sill = {sill:.5f} | range = {range_:.1f})')\n",
    "    plt.show()\n",
    "    \n",
    "    return inter_map_kriging\n",
    "    \n",
    "semivariance = pdist(np.asarray(data_df['Z']).reshape(-1, 1), metric='sqeuclidean') / 2\n",
    "interactive_kriging_figure = interactive(interactive_ordinary_kriging, \n",
    "            variogram = ['spherical','gaussian','exponential'], \n",
    "            sill = (0,np.mean(semivariance)*2,np.mean(semivariance)/10), range_ = (1,100), num_bins = (5,40))\n",
    "display(interactive_kriging_figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356c5f68",
   "metadata": {},
   "source": [
    "#### Save the interpolated map as a raster file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a6def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the interpolated map as a variable\n",
    "inter_map_kriging = interactive_kriging_figure.result\n",
    "inter_map_kriging[np.isnan(dem)] = np.nan\n",
    "\n",
    "# Define the output file path\n",
    "output_path = f'Case_studies/{case_study.value}/{data_folder.value}/'\n",
    "output_file = f'{data_type}_interpolated_map(ordinary kriging).tif'\n",
    "\n",
    "save_as_raster(output_path, output_file, inter_map_kriging, metadata)\n",
    "\n",
    "print(f\"Interpolated map saved to: {output_path+output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bcdb18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
